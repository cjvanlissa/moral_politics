Line 54-56:
-Setting a seed in the main R session does not set it in the sessions running on the separate clusters. This makes that results can not replicated. My solution now is passing a vector of seeds the size of the hypergrid to all separate clusters. Setting a seed belonging to the condition within the foreach loop does replicate the results. However, I am wondering, as the conditions become very big, the vector of seeds also becomes very big. Does passing a large vector to all separate clusters impair performance? Every cluster has its own set of registers and are they at risk of overloading?

in 'functions.R' in the simdata() function, I am unsure whether how the data is simulated is correct. Each iteration of the simulation simulates k datasets of 2 variables, of which one is the predictor and the other is the outcome. They are currently generated using mvrnorm() where both variables have a mean of 0 and an sd of 1. The reliability for one specific dataset is simulated by generating a value from a normal distribution with mean = true_es and sd = sqrt(tau2). However, as the true_es gets more extreme (close to 1 or -1) and tau2 gets larger, then the probability of the drawn rho being larger than 1 or smaller than -1 increases. I now solved it with a while loop, but is there a better way to implement some variation in the reliability?

in 'functions.R' in the BFs() function, line 29: 
-The sample size for a specific group is drawn from a normal with mean = n and sd = n/3. In line 25, I make sure that the sample size is at least 10. This number is quite arbitrary and I am wondering if there is a minimum required sample size?

Line 46-54: 
-I call bain on all individual hypotheses; r_k > hyp_value. I pass for every call a named vector of estimates of the effect size and a list of standard error estimates of these effect sizes. I also state that the number of group_parameters is 1 (rho_xy), while there is no shared parameters between groups. I am wondering if this is correct or that some kind of for loop must be implemented where just one estimate per call is passed instead of all estimates?

line 65:
- in the bf_together, bain is called once on (r1, r2, .., rk) > hyp_val. Should n be the total sample size combined in all groups?